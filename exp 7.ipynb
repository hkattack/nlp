{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68605c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: eat apple\n",
      "POS Tags: ['Noun', 'Noun']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Transition probabilities\n",
    "transition_probs = {\n",
    "    'Noun': {'Noun': 0.7, 'Verb': 0.3},\n",
    "    'Verb': {'Noun': 0.4, 'Verb': 0.6}\n",
    "}\n",
    "\n",
    "# Emission probabilities\n",
    "emission_probs = {\n",
    "    'Noun': {'apple': 0.4, 'banana': 0.6},\n",
    "    'Verb': {'eat': 0.8, 'run': 0.2}\n",
    "}\n",
    "\n",
    "# POS tags\n",
    "pos_tags = ['Noun', 'Verb']\n",
    "\n",
    "def viterbi(sentence):\n",
    "    words = sentence.split()\n",
    "    n = len(words)\n",
    "    num_tags = len(pos_tags)\n",
    "    \n",
    "    # Initialize the Viterbi matrix and backpointers\n",
    "    viterbi_matrix = np.zeros((num_tags, n))\n",
    "    backpointers = np.zeros((num_tags, n), dtype=int)\n",
    "    \n",
    "    # Initialization step\n",
    "    for i in range(num_tags):\n",
    "        viterbi_matrix[i, 0] = transition_probs[pos_tags[i]].get('Start', 0) * emission_probs[pos_tags[i]].get(words[0], 0)\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(1, n):\n",
    "        for s in range(num_tags):\n",
    "            max_prob = -1\n",
    "            max_prob_index = -1\n",
    "            for prev_s in range(num_tags):\n",
    "                prob = viterbi_matrix[prev_s, t-1] * transition_probs[pos_tags[prev_s]].get(pos_tags[s], 0) * emission_probs[pos_tags[s]].get(words[t], 0)\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_prob_index = prev_s\n",
    "            viterbi_matrix[s, t] = max_prob\n",
    "            backpointers[s, t] = max_prob_index\n",
    "    \n",
    "    # Termination step\n",
    "    max_final_prob = -1\n",
    "    max_final_prob_index = -1\n",
    "    for s in range(num_tags):\n",
    "        final_prob = viterbi_matrix[s, n-1] * transition_probs[pos_tags[s]].get('End', 0)\n",
    "        if final_prob > max_final_prob:\n",
    "            max_final_prob = final_prob\n",
    "            max_final_prob_index = s\n",
    "    \n",
    "    # Traceback to find the most likely sequence of POS tags\n",
    "    pos_tag_sequence = []\n",
    "    pos_tag_sequence.append(pos_tags[max_final_prob_index])\n",
    "    prev_tag_index = max_final_prob_index\n",
    "    for t in range(n-1, 0, -1):\n",
    "        prev_tag_index = backpointers[prev_tag_index, t]\n",
    "        pos_tag_sequence.insert(0, pos_tags[prev_tag_index])\n",
    "    \n",
    "    return pos_tag_sequence\n",
    "\n",
    "# Test the Viterbi algorithm\n",
    "sentence = \"eat apple\"\n",
    "tag_sequence = viterbi(sentence)\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"POS Tags:\", tag_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b220ce3",
   "metadata": {},
   "source": [
    "The Viterbi algorithm is a dynamic programming algorithm used to find the most likely sequence of hidden states (in this case, POS tags) given a sequence of observations (in this case, words). It is commonly used in Hidden Markov Models (HMM) to solve decoding problems.\n",
    "\n",
    "Here is a step-by-step explanation of the Viterbi algorithm implemented in the code:\n",
    "\n",
    "1. Import the necessary libraries, including `numpy` for matrix operations.\n",
    "\n",
    "2. Define the transition probabilities (`transition_probs`), emission probabilities (`emission_probs`), and POS tags (`pos_tags`) specific to your application.\n",
    "\n",
    "3. Define the `viterbi` function that takes a sentence as input.\n",
    "\n",
    "4. Split the input sentence into individual words and obtain the number of words (`n`) and the number of POS tags (`num_tags`).\n",
    "\n",
    "5. Create two matrices: `viterbi_matrix` and `backpointers`. The `viterbi_matrix` keeps track of the maximum probabilities at each state and time step, and the `backpointers` matrix stores the indices of the previous states that led to the maximum probabilities.\n",
    "\n",
    "6. Initialize the first column of the `viterbi_matrix` with the initial probabilities calculated from the transition and emission probabilities for the first word.\n",
    "\n",
    "7. Iterate through the remaining time steps (words) of the sentence:\n",
    "\n",
    "   - For each state (POS tag) at the current time step, calculate the maximum probability of transitioning from the previous states and emitting the current word.\n",
    "   - Update the corresponding cell in the `viterbi_matrix` with the maximum probability.\n",
    "   - Update the corresponding cell in the `backpointers` matrix with the index of the previous state that led to the maximum probability.\n",
    "\n",
    "8. After iterating through all time steps, find the maximum final probability in the last column of the `viterbi_matrix` and the corresponding index.\n",
    "\n",
    "9. Trace back through the `backpointers` matrix to determine the most likely sequence of POS tags.\n",
    "\n",
    "10. Return the sequence of POS tags.\n",
    "\n",
    "11. Prompt the user to enter a sentence.\n",
    "\n",
    "12. Apply the `viterbi` function to the input sentence to obtain the most likely sequence of POS tags.\n",
    "\n",
    "13. Print the original sentence and the corresponding POS tags.\n",
    "\n",
    "The code allows you to customize the transition and emission probabilities (`transition_probs` and `emission_probs`) to suit your specific application or dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
