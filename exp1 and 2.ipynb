{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351dca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae25f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Kunal', 'Chawla', '.', 'I', 'have', 'great', 'communication', 'skills', '.', 'I', 'study', 'in', 'Chnadigarh', 'University']\n",
      "['My  name is Kunal Chawla.', 'I have great communication skills.', 'I study in Chnadigarh University']\n"
     ]
    }
   ],
   "source": [
    "#tokenization using NLTK\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "sent=\"My  name is Kunal Chawla. I have great communication skills. I study in Chnadigarh University\"\n",
    "print(word_tokenize(sent))\n",
    "print(sent_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c718d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my\n",
      "name\n",
      "is\n",
      "kunal\n",
      "chawla\n",
      ".\n",
      "i\n",
      "have\n",
      "great\n",
      "commun\n",
      "skill\n",
      ".\n",
      "i\n",
      "studi\n",
      "in\n",
      "chnadigarh\n",
      "univers\n"
     ]
    }
   ],
   "source": [
    "#porter stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "word=['My', 'name', 'is', 'Kunal', 'Chawla', '.', 'I', 'have', 'great', 'communication', 'skills', '.', 'I', 'study', 'in', 'Chnadigarh', 'University']\n",
    "stem_words=[]\n",
    "for w in word:\n",
    "    x=porter.stem(w)\n",
    "    stem_words.append(x)\n",
    "for e in stem_words:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4126d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my\n",
      "name\n",
      "is\n",
      "kunal\n",
      "chawla\n",
      ".\n",
      "i\n",
      "have\n",
      "great\n",
      "communic\n",
      "skill\n",
      ".\n",
      "i\n",
      "studi\n",
      "in\n",
      "chnadigarh\n",
      "univers\n"
     ]
    }
   ],
   "source": [
    "#snowball stemming\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snow_stemmer=SnowballStemmer(language='english')\n",
    "word=['My', 'name', 'is', 'Kunal', 'Chawla', '.', 'I', 'have', 'great', 'communication', 'skills', '.', 'I', 'study', 'in', 'Chnadigarh', 'University']\n",
    "stem_words=[]\n",
    "for w in word:\n",
    "    x=snow_stemmer.stem(w)\n",
    "    stem_words.append(x)\n",
    "for e in stem_words:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe5c481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Kunal\n",
      "[nltk_data]     Chawla\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c38478c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My\n",
      "name\n",
      "is\n",
      "Kunal\n",
      "Chawla\n",
      ".\n",
      "I\n",
      "have\n",
      "great\n",
      "communication\n",
      "skill\n",
      ".\n",
      "I\n",
      "study\n",
      "in\n",
      "Chnadigarh\n",
      "University\n"
     ]
    }
   ],
   "source": [
    "#lemmetization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "word=['My', 'name', 'is', 'Kunal', 'Chawla', '.', 'I', 'have', 'great', 'communication', 'skills', '.', 'I', 'study', 'in', 'Chnadigarh', 'University']\n",
    "stem_words=[]\n",
    "for w in word:\n",
    "    x=lemmatizer.lemmatize(w)\n",
    "    stem_words.append(x)\n",
    "for e in stem_words:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e98137",
   "metadata": {},
   "source": [
    "Tokenization, stemming, and lemmatization are techniques used in natural language processing (NLP) and text mining to preprocess textual data.\n",
    "\n",
    "1. Tokenization:\n",
    "Tokenization is the process of breaking a text into individual tokens or words. The tokens can be words, sentences, or even smaller units like characters or subwords. The main goal of tokenization is to divide the text into meaningful units to facilitate further analysis. For example, consider the sentence \"Tokenization is an important NLP technique.\" After tokenization, it can be represented as [\"Tokenization\", \"is\", \"an\", \"important\", \"NLP\", \"technique\"].\n",
    "\n",
    "There are different types of tokenization techniques, including:\n",
    "- Word Tokenization: It breaks the text into words based on whitespace or punctuation.\n",
    "- Sentence Tokenization: It divides the text into sentences based on punctuation marks or specific patterns.\n",
    "- Character Tokenization: It splits the text into individual characters.\n",
    "- Subword Tokenization: It breaks the text into meaningful subword units, which can be useful for languages with complex word formations.\n",
    "\n",
    "2. Stemming:\n",
    "Stemming is a process that reduces words to their base or root form, called a stem. It involves removing prefixes, suffixes, and sometimes reducing the word to its core form. The resulting stem may not always be a valid word. For example, the stem of the words \"running,\" \"runs,\" and \"run\" would be \"run.\"\n",
    "\n",
    "Stemming algorithms apply specific rules to truncate words, but they may not always produce accurate stems. Popular stemming algorithms include the Porter stemming algorithm, Snowball stemming algorithm, and Lancaster stemming algorithm.\n",
    "\n",
    "3. Lemmatization:\n",
    "Lemmatization is similar to stemming, but it aims to determine the base or dictionary form of a word, which is known as the lemma. Unlike stemming, lemmatization considers the context and part of speech (POS) of the word to produce valid lemmas. For example, the lemma of \"running,\" \"runs,\" and \"run\" would all be \"run.\"\n",
    "\n",
    "Lemmatization algorithms use lexical knowledge resources like dictionaries, word corpora, or POS tagging to map words to their lemmas accurately. It produces meaningful lemmas that are valid words in a language.\n",
    "\n",
    "Both stemming and lemmatization help in reducing words to their core forms, but lemmatization generally produces better results as it considers the linguistic context and maintains the integrity of the language.\n",
    "\n",
    "In summary, tokenization breaks text into meaningful units, stemming reduces words to their base form by removing affixes, and lemmatization determines the base form of words while considering their context and POS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
